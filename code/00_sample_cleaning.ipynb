{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßº Dataset Cleaning ‚Äì Mexican Labor Market Project\n",
    "\n",
    "This notebook is dedicated to the cleaning and preparation of microdata files from Banco de M√©xico‚Äôs Local Labor Market Database. These files contain census-based individual-level information on employment, income, demographics, and other variables from the years 1990 to 2020.\n",
    "\n",
    "### Objectives:\n",
    "- Load and inspect `.txt` files containing population and labor data.\n",
    "- Combine \"Informacion Personas\" datasets across years into one unified dataset.\n",
    "- Merge relevant complementary datasets (e.g., income) by `ANIO` and `ID_PERSONA`.\n",
    "- Prepare the final clean dataset for further analysis in classification, regression, and clustering models.\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: Since `ID_PERSONA` is not traceable across years, all analysis will treat individuals as part of repeated cross-sectional samples rather than a panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÅ Step 1: Define the Raw Data Directory\n",
    "\n",
    "We define the path to the `rawdata` folder where all `.txt` files are stored. This will be used to locate and load the sample files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Reading sample from: Informacion Personas 2000_0.txt\n",
      "‚úÖ Loaded 800 rows, 66 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2000_1.txt\n",
      "‚úÖ Loaded 800 rows, 66 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2020_0.txt\n",
      "‚úÖ Loaded 800 rows, 65 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2020_1.txt\n",
      "‚úÖ Loaded 800 rows, 65 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Derechohabiencia.txt\n",
      "‚úÖ Loaded 800 rows, 3 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 1990_0.txt\n",
      "‚úÖ Loaded 800 rows, 66 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Prestaciones.txt\n",
      "‚úÖ Loaded 800 rows, 3 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Discapacidades.txt\n",
      "‚úÖ Loaded 800 rows, 4 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2010_1.txt\n",
      "‚úÖ Loaded 800 rows, 65 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2010_0.txt\n",
      "‚úÖ Loaded 800 rows, 65 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Ingresos.txt\n",
      "‚úÖ Loaded 800 rows, 4 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2015_2.txt\n",
      "‚úÖ Loaded 800 rows, 65 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2015_0.txt\n",
      "‚úÖ Loaded 800 rows, 65 columns\n",
      "\n",
      "üìÑ Reading sample from: Informacion Personas 2015_1.txt\n",
      "‚úÖ Loaded 800 rows, 65 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set your folder path\n",
    "project_dir = os.path.dirname(\"/Users/anahirm/Library/CloudStorage/OneDrive-EcolePolytechnique/Polytecnique/Introduction to Machine Learning/\")  # or just use os.getcwd() if you're already in the right place\n",
    "folder_path = os.path.join(project_dir, \"Project-data/\", \"rawdata\")\n",
    "\n",
    "# Step 2: Find all .txt files in the folder\n",
    "file_paths = glob(os.path.join(folder_path, '*.txt'))\n",
    "\n",
    "# Step 3: Read a sample (e.g. 100 rows) from each file\n",
    "sample_data = {}\n",
    "\n",
    "for path in file_paths:\n",
    "    file_name = os.path.basename(path)\n",
    "    print(f\"üìÑ Reading sample from: {file_name}\")\n",
    "    \n",
    "    try:\n",
    "        df_sample = pd.read_csv(path, encoding='latin-1', nrows=800, low_memory=False)\n",
    "        sample_data[file_name] = df_sample\n",
    "        print(f\"‚úÖ Loaded {df_sample.shape[0]} rows, {df_sample.shape[1]} columns\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not read {file_name}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Step 2: Display Dataset Names and Sample Sizes\n",
    "\n",
    "We display the names and dimensions (rows and columns) of the datasets that were loaded into memory. This allows us to verify that the sample reading was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Overview of loaded sample datasets:\n",
      "\n",
      "Informacion Personas 2000_0.txt          ‚Üí  Rows:   800,  Columns: 66\n",
      "Informacion Personas 2000_1.txt          ‚Üí  Rows:   800,  Columns: 66\n",
      "Informacion Personas 2020_0.txt          ‚Üí  Rows:   800,  Columns: 65\n",
      "Informacion Personas 2020_1.txt          ‚Üí  Rows:   800,  Columns: 65\n",
      "Informacion Derechohabiencia.txt         ‚Üí  Rows:   800,  Columns: 3\n",
      "Informacion Personas 1990_0.txt          ‚Üí  Rows:   800,  Columns: 66\n",
      "Informacion Prestaciones.txt             ‚Üí  Rows:   800,  Columns: 3\n",
      "Informacion Discapacidades.txt           ‚Üí  Rows:   800,  Columns: 4\n",
      "Informacion Personas 2010_1.txt          ‚Üí  Rows:   800,  Columns: 65\n",
      "Informacion Personas 2010_0.txt          ‚Üí  Rows:   800,  Columns: 65\n",
      "Informacion Ingresos.txt                 ‚Üí  Rows:   800,  Columns: 4\n",
      "Informacion Personas 2015_2.txt          ‚Üí  Rows:   800,  Columns: 65\n",
      "Informacion Personas 2015_0.txt          ‚Üí  Rows:   800,  Columns: 65\n",
      "Informacion Personas 2015_1.txt          ‚Üí  Rows:   800,  Columns: 65\n"
     ]
    }
   ],
   "source": [
    "# Print the name and size (rows, columns) of each dataset in the dictionary\n",
    "print(\"üìä Overview of loaded sample datasets:\\n\")\n",
    "\n",
    "for name, df in sample_data.items():\n",
    "    print(f\"{name:<40} ‚Üí  Rows: {df.shape[0]:>5},  Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Step 3: Combine All Years into a Single Dataset\n",
    "\n",
    "We concatenate the \"Informacion Personas\" datasets from all available years into one combined dataset called `all_personas`. Each row retains its original year through the `ANIO` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Combined sample dataset: 8,000 rows, 66 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANIO</th>\n",
       "      <th>ID_PERSONA</th>\n",
       "      <th>LLAVE_ENTIDAD</th>\n",
       "      <th>LLAVE_MUNICIPIO</th>\n",
       "      <th>CLAVE_MUNICIPIO_INEGI(CLAVE_DE_AGEM)</th>\n",
       "      <th>LLAVE_LOCALIDAD</th>\n",
       "      <th>CLAVE_LOCALIDAD_INEGI</th>\n",
       "      <th>ID_VIVIENDA</th>\n",
       "      <th>ID_HOGAR</th>\n",
       "      <th>LLAVE_COBERTURA</th>\n",
       "      <th>...</th>\n",
       "      <th>NUMPERSONA</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>ESCOLARIDAD</th>\n",
       "      <th>ESCOLARIDAD_ACUMULADA</th>\n",
       "      <th>INGRESO</th>\n",
       "      <th>HORAS_TRABAJADAS</th>\n",
       "      <th>HIJOS_NACIDOS</th>\n",
       "      <th>HIJOS_VIVOS</th>\n",
       "      <th>HIJOS_FALLECIDOS</th>\n",
       "      <th>MERCADO_TRABAJO_LOCAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>200000000000000005147</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>170001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000000000000001</td>\n",
       "      <td>2.000000e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>200000000000000005154</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>170001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000000000002444</td>\n",
       "      <td>2.000000e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>200000000000000005162</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>170001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000000000004887</td>\n",
       "      <td>2.000000e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>200000000000000005172</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>170001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000000000007330</td>\n",
       "      <td>2.000000e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2357.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>200000000000000005179</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>170001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000000000012214</td>\n",
       "      <td>2.000000e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANIO             ID_PERSONA  LLAVE_ENTIDAD  LLAVE_MUNICIPIO  \\\n",
       "0  2000  200000000000000005147              1               17   \n",
       "1  2000  200000000000000005154              1               17   \n",
       "2  2000  200000000000000005162              1               17   \n",
       "3  2000  200000000000000005172              1               17   \n",
       "4  2000  200000000000000005179              1               17   \n",
       "\n",
       "   CLAVE_MUNICIPIO_INEGI(CLAVE_DE_AGEM)  LLAVE_LOCALIDAD  \\\n",
       "0                                     1           170001   \n",
       "1                                     1           170001   \n",
       "2                                     1           170001   \n",
       "3                                     1           170001   \n",
       "4                                     1           170001   \n",
       "\n",
       "   CLAVE_LOCALIDAD_INEGI       ID_VIVIENDA      ID_HOGAR  LLAVE_COBERTURA  \\\n",
       "0                    1.0  2000000000000001  2.000000e+15                0   \n",
       "1                    1.0  2000000000002444  2.000000e+15                0   \n",
       "2                    1.0  2000000000004887  2.000000e+15                0   \n",
       "3                    1.0  2000000000007330  2.000000e+15                0   \n",
       "4                    1.0  2000000000012214  2.000000e+15                0   \n",
       "\n",
       "   ...  NUMPERSONA  EDAD  ESCOLARIDAD  ESCOLARIDAD_ACUMULADA  INGRESO  \\\n",
       "0  ...         NaN  19.0          6.0                    6.0   1929.0   \n",
       "1  ...         NaN  30.0          5.0                    5.0   2143.0   \n",
       "2  ...         NaN  17.0          9.0                    NaN      0.0   \n",
       "3  ...         NaN  18.0          4.0                    4.0   2357.0   \n",
       "4  ...         NaN  24.0          3.0                    9.0   1929.0   \n",
       "\n",
       "   HORAS_TRABAJADAS  HIJOS_NACIDOS  HIJOS_VIVOS  HIJOS_FALLECIDOS  \\\n",
       "0               NaN            NaN          NaN               NaN   \n",
       "1              54.0            NaN          NaN               NaN   \n",
       "2               NaN            NaN          NaN               NaN   \n",
       "3              54.0            NaN          NaN               NaN   \n",
       "4              53.0            NaN          NaN               NaN   \n",
       "\n",
       "   MERCADO_TRABAJO_LOCAL  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Filter only \"Informacion Personas\" files\n",
    "personas_parts = {\n",
    "    name: df for name, df in sample_data.items()\n",
    "    if \"Informacion Personas\" in name\n",
    "}\n",
    "\n",
    "# Step 2: Group files by year extracted from the filename\n",
    "personas_by_year = defaultdict(list)\n",
    "\n",
    "for file_name, df in personas_parts.items():\n",
    "    try:\n",
    "        year = file_name.split()[2][:4]  # Get year from \"Informacion Personas 2015_0.txt\"\n",
    "        personas_by_year[year].append(df)\n",
    "    except IndexError:\n",
    "        print(f\"‚ö†Ô∏è Could not extract year from: {file_name}\")\n",
    "\n",
    "# Step 3: Concatenate all parts per year\n",
    "full_personas_by_year = {\n",
    "    year: pd.concat(dfs, ignore_index=True)\n",
    "    for year, dfs in personas_by_year.items()\n",
    "}\n",
    "\n",
    "# Step 4: Combine all years into one DataFrame\n",
    "sample_all_personas = pd.concat(\n",
    "    full_personas_by_year.values(),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Step 5: Print the shape and preview\n",
    "print(f\"üßæ Combined sample dataset: {sample_all_personas.shape[0]:,} rows, {sample_all_personas.shape[1]} columns\")\n",
    "sample_all_personas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File saved to: /Users/anahirm/Library/CloudStorage/OneDrive-EcolePolytechnique/Polytecnique/Introduction to Machine Learning/Project-data/cleandata/sample_all_personas.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the full path to the file\n",
    "save_path = os.path.join(project_dir, \"Project-data\", \"cleandata\", \"sample_all_personas.csv\")\n",
    "\n",
    "# Save the DataFrame\n",
    "#sample_all_personas.to_csv(save_path, index=False, encoding='utf-8')\n",
    "\n",
    "#print(f\"‚úÖ File saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
